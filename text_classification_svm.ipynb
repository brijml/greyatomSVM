{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import all the necessary packages. Sklearn is the most essential library used that provides feature extraction, training SVM and evaluating the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset. Pandas is a data analysis library that lets you read the csv file from disk and load it to the working memory for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('text_classification_dataset.csv')\n",
    "data = shuffle(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a little preprocessing of the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions_mapping = {\"i'm\": 'i am',\n",
    " \"i've\": 'i have',\n",
    " \"you're\": 'you are',\n",
    " 'dont': 'do not',\n",
    " \"don't\": 'do not',\n",
    " \"can't\": 'can not',\n",
    " 'cant': 'can not',\n",
    " \"what's\": 'what is',\n",
    " 'whats': 'what is',\n",
    " \"how's\": 'how is',\n",
    " 'hows': 'how is',\n",
    " \"\\\\'nt\": 'not',\n",
    " '^\\\\w\\\\s': '',\n",
    " \"\\\\'s\": '',\n",
    " '\\\\n': ' '}\n",
    "\n",
    "def regex_clean(doc):\n",
    "    doc = doc.lower()\n",
    "    for k,v in contractions_mapping.items():\n",
    "        doc = re.sub(k,v,doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['reviews'] = data['reviews'].apply(lambda x:regex_clean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to use Tfidf for feature extraction. TfIdf score is the score that calculates the relative importance for each term in the vocabulary. The idea behind tfidf score is that the words stop words like \"the\", \"is\", \"a\" etc are more frequent in the vocabulary, therefore these words should have lesser importance as compared to \"awesome\", \"amazing\", \"awful\" etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word')\n",
    "tfidf.fit(data['reviews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idf value for 'the' is 1.8100142746060173\n",
      "idf value for 'and' is 2.158695570864004\n",
      "idf value for 'not' is 3.0278150805392454\n",
      "idf value for 'good' is 3.6130732990880055\n",
      "idf value for 'bad' is 4.495841338923517\n",
      "idf value for 'amazing' is 5.451352783950954\n",
      "idf value for 'awful' is 5.915658392082051\n",
      "idf value for 'awesome' is 5.962178407716944\n"
     ]
    }
   ],
   "source": [
    "word_list = ['the', 'and', 'not', 'good', 'bad', 'amazing', 'awful', 'awesome']\n",
    "for word in word_list:\n",
    "    print(\"idf value for '{}' is {}\".format(word, tfidf.idf_[tfidf.vocabulary_[word]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = list(train['reviews']), list(train['labels'])\n",
    "X_test, Y_test = list(test['reviews']), list(test['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_X_train = tfidf.transform(X_train)\n",
    "tfidf_X_test = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(tfidf_X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8066666666666666"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(tfidf_X_test)\n",
    "accuracy_score(Y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>label</th>\n",
       "      <th>predicition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>my salad had a bland vinegrette on the baby gr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>they have great dinners.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>have read other reviews here but i haven't had...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>the story which was told so eloquently by fran...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>the keyboard is really worthwhile in usefulnes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>it a shame to see good actors like thomerson a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>you'd have to have the iq of particularly stup...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>for about 10 minutes, we we're waiting for her...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>the incredible soundtrack truly captures the e...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>the attractive set used throughout most of the...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sample  label  predicition\n",
       "109  my salad had a bland vinegrette on the baby gr...      0            0\n",
       "431                           they have great dinners.      1            1\n",
       "9    have read other reviews here but i haven't had...      1            1\n",
       "27   the story which was told so eloquently by fran...      1            1\n",
       "421  the keyboard is really worthwhile in usefulnes...      1            1\n",
       "409  it a shame to see good actors like thomerson a...      0            1\n",
       "144  you'd have to have the iq of particularly stup...      0            0\n",
       "274  for about 10 minutes, we we're waiting for her...      0            0\n",
       "271  the incredible soundtrack truly captures the e...      1            1\n",
       "244  the attractive set used throughout most of the...      1            1"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'sample':X_test, \"label\":Y_test, \"predicition\": preds})\n",
    "df.sample(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(tfidf.transform([\"The movie is bad\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(tfidf.transform([\"The movie is not bad\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
